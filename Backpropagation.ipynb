{
 "metadata": {
  "name": "",
  "signature": "sha256:2c0196bb5c0d3ac03fdcd6338ac684cdbe08c14bb5c6090c0ea8656feecf9ee0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Training a FNN (MLP) with Backpropagation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Notation\n",
      "\n",
      "Following the notation of ``Supervised Sequence Labelling with Recurrent Neural Networks'' (Graves 2012):\n",
      "\n",
      "$I$ - Number of input units\n",
      "\n",
      "$x_i$ - $i$th entry of the input vector $x$\n",
      "\n",
      "$H_l$ - Number of hidden units in hidden layer $l$\n",
      "\n",
      "$w_{ij}$ - Weight from unit $i$ to $j$\n",
      "\n",
      "$\\theta_h$ - Activation function for hidden unit $h$; typically\n",
      "\n",
      "$$\\theta_h = \\mathrm{tanh}(x) = \\frac{e^{2x} - 1}{e^{2x} + 1} \\;\\mathrm{or}\\; \\theta_h = \\sigma(x) = \\frac{1}{1 + e^{-x}}$$\n",
      "\n",
      "for hidden layers.  Softmax, typically used on the output layer, estimates the probability of class $C_k$ by\n",
      "\n",
      "$$\\theta_h = p(C_k | x) = \\frac{e^{a_k}}{\\sum_{k^\\prime}^{H_l} e^{a_{k^\\prime}}}$$\n",
      "\n",
      "$b_h$ - Output of unit $h$, $b_h = \\theta_h(a_h)$\n",
      "\n",
      "$a_h$ - Network input to hidden unit $h$, computed as \n",
      "\n",
      "$$a_h = \\sum_{i = 1}^I w_{ih} x_i$$\n",
      "\n",
      "for units connected to the input layer and\n",
      "\n",
      "$$a_h = \\sum_{h^\\prime = 1}^{H_{l - 1}} w_{h^\\prime h}b_{h^\\prime}$$\n",
      "\n",
      "$m$ - Number of layers in the neural network\n",
      "\n",
      "$S$ - Training set of tuples $(x, z)$ corresponding to a data vector $x$ and its label $z$.  For a multiclass classification problem with $K$ classes, $z \\in \\mathbb{R}^K$ is a vector where $z_k = 1$ when the class of $x$ is $k$ and is $0$ otherwise.\n",
      "\n",
      "$y_k$ - the output ($b_k$) of the $k$th unit of the output layer.\n",
      "\n",
      "$O$ - Objective function for training the neural network; for softmax output function with cross-entropy error\n",
      "\n",
      "$$O = -\\sum_{(x, z) \\in S} \\sum_{k = 1}^K z_k \\log(y_k)$$\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Backpropagation\n",
      "\n",
      "We will consider the use of backpropagation to train a feedforward neural network (multilayer perceptron) with sigmoid activation and softmax output.  Backpropagation is the repeated application of the chain rule for partial derivatives computed on the objective of the neural network function.  Differentiating the softmax activation objective $O$ above with respect to the network output $y_k$ we have\n",
      "\n",
      "$$\\frac{\\partial O}{\\partial y_k} = -\\frac{z_k}{y_k}$$\n",
      "\n",
      "and by the chain rule we have \n",
      "\n",
      "$$\\frac{\\partial O}{\\partial a} = \\frac{\\partial O}{\\partial y}\\frac{\\partial y}{\\partial a}$$\n",
      "\n",
      "Since the neural network output depends on the network input to every unit in the layer, we can apply the chain rule again to get\n",
      "\n",
      "$$\\frac{\\partial O}{\\partial a_k} = \\sum_{k^\\prime = 1}^K \\frac{\\partial O}{\\partial y_{k^\\prime}} \\frac{\\partial y_{k^\\prime}}{\\partial a_k}$$\n",
      "\n",
      "Now, we can differentiate the softmax function to obtain\n",
      "\n",
      "$$\\frac{\\partial y_{k^\\prime}}{\\partial a_k} = y_k \\delta_{kk^\\prime} - y_k y_{k^\\prime}$$\n",
      "\n",
      "Substituting, we have\n",
      "\n",
      "\\begin{align*}\n",
      "\\frac{\\partial O}{\\partial a_k} &= \\sum_{k^\\prime = 1}^K -\\frac{z_{k^\\prime}}{y_{k^\\prime}} (y_k \\delta_{kk^\\prime} - y_k y_{k^\\prime})\\\\\n",
      "&= -z_k + \\sum_{k^\\prime = 1}^K \\frac{z_{k^\\prime}}{y_{k^\\prime}}y_k y_{k^\\prime}\\\\\n",
      "&= y_k - z_k\n",
      "\\end{align*}\n",
      "\n",
      "because $\\sum_k z_k = 1$.  Continuing for the other activations, we have\n",
      "\n",
      "$$\\frac{\\partial O}{a_h} = \\frac{\\partial O}{\\partial b_h} \\frac{\\partial b_h}{\\partial a_h} = \\frac{\\partial b_h}{\\partial a_h} \\sum_{k = 1}^{H_{l - 1}} \\frac{\\partial O}{\\partial a_k} \\frac{\\partial a_k}{\\partial b_h}$$\n",
      "\n",
      "where we have used the chain rule twice and have exploited the fact that the $O$ only depends on a hidden unit $h$ through its influence on the output units.  If we differentiate our definition of $a_k$, we can compute the derivatives for the last hidden layer\n",
      "\n",
      "$$\n",
      "\\frac{\\partial O}{a_h} = \\theta^\\prime(a_j) \\sum_{k = 1}^K \\frac{\\partial O}{\\partial a_k} w_{hk}\n",
      "$$\n",
      "\n",
      "and recursively for each hidden layer $l$\n",
      "\n",
      "$$\n",
      "\\frac{\\partial O}{a_h} = \\theta^\\prime(a_h) \\sum_{h^\\prime = 1}^{H_{l + 1}} \\frac{\\partial O}{\\partial a_{h^\\prime}} w_{h h^\\prime}\n",
      "$$\n",
      "\n",
      "Finally, we can compute the derivative of the objective function with respect to the network weights by\n",
      "\n",
      "$$\n",
      "\\frac{\\partial O}{\\partial w_{ij}} = \\frac{\\partial O}{\\partial a_j} \\frac{\\partial a_j}{\\partial w_{ij}} = \\frac{\\partial O}{\\partial a_{j}} b_i$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Notation\n",
      "\n",
      "$L$ - Number of layers in the network.\n",
      "\n",
      "$N^n$ - Dimensionality of layer $n \\in \\{0, \\ldots, L\\}$.  $N^0$ is the dimensionality of the input; $N^L$ is the dimensionality of the output.\n",
      "\n",
      "$W^m \\in \\mathbb{R}^{N^{m - 1} \\times N^m}$ - Weight matrix for layer $m \\in \\{1, \\ldots, L\\}$.  $W^m_{ij}$ is the weight between the $i^{th}$ unit in layer $m - 1$ and the $j^{th}$ unit in layer $m$.\n",
      "\n",
      "$b^m \\in \\mathbb{R}^{N^m}$ - Bias vector for layer $m$.\n",
      "\n",
      "$\\sigma^m$ - Nonlinear activation function of the units in layer $m$, applied elementwise.\n",
      "\n",
      "$h^m \\in \\mathbb{R}^{N^m}$ - Linear mix of the inputs to layer $m$, computed by $h^m = W^m a^{m - 1} + b^m$.\n",
      "\n",
      "$a^m \\in \\mathbb{R}^{N^m}$ - Activation of units in layer $m$, computed by $a^m = \\sigma^m(h^m) = \\sigma^m(W^m a^{m - 1} + b^m)$.  $a^L$ is the output of the network.  We define the special case $a^0$ as the input of the network.\n",
      "\n",
      "$z \\in \\mathbb{R}^{N^L}$ - Target output of the network"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Backpropagation\n",
      "\n",
      "We will derive the backpropogation algorithm for a neural network with a logistic activation function on all layers; that is \n",
      "\n",
      "$$\\sigma^m(x) = \\frac{1}{1 + e^{x}}$$\n",
      "\n",
      "for all $m \\in \\{1, \\ldots, L\\}$.  The logistic activation function has derivative\n",
      "\n",
      "$$\\frac{\\partial \\sigma^m}{\\partial x} = \\sigma^m(x)(1 - \\sigma^m(x))$$\n",
      "\n",
      "Because the network is updated for each training example individually, we will perform all derivations for a single training vector $x$ and a target $z$.  We will use the squared error function\n",
      "\n",
      "$$E = \\frac{1}{2}(z - a^L)^\\top(z - a^L)$$\n",
      "\n",
      "In order to train the network using a gradient descent algorithm, we need to know the gradient of each of the parameters with respect to the error function $\\frac{\\partial E}{\\partial W^m}$ and $\\frac{\\partial E}{\\partial b^m}$.  In order to compute the gradient of our error function to $W^m_{ij}$ (a single entry in the weight matrix of the layer $m$), we can use the chain rule (from The Matrix Cookbook, \u00a72.8.1):\n",
      "\n",
      "$$\\frac{\\partial E}{\\partial W^m_{ij}} = \\sum_{k = 1}^{N^m} \\frac{\\partial E}{\\partial a^m_k} \\frac{\\partial a^m_k}{\\partial W^m_{ij}}$$\n",
      "\n",
      "Note that the second term will evaluate to zero when $i \\ne k$ because $a^m_k$ does not interact with any elements in $W^m$ except for those in the $k$th row, and we are only considering the entry $W^m_{ij}$.  When $i = k$, we require a second invocation of the chain rule due to the fact that $a^m$ is a composite function of $\\sigma^m$ and the linear mix function $h^m$.  In this case, we have\n",
      "\n",
      "\\begin{align*}\n",
      "\\frac{\\partial a^m_i}{\\partial W^m_{ij}} &= \\frac{\\partial a^m_i}{\\partial h^m_i} \\frac{\\partial h^m_i}{\\partial W^m_{ij}}\\\\\n",
      "&= \\frac{\\partial}{\\partial h^m_i} (\\sigma^m(h^m_i)) \\frac{\\partial}{\\partial W^m_{ij}}(W^m a^{m - 1} + b^m)\\\\\n",
      "&= a^m_i(1 - a^m_i) a^{m - 1}_j\\\\\n",
      "\\rightarrow \\frac{\\partial a^m_k}{\\partial W^m_{ij}} &= \\begin{cases}\n",
      "0 & k \\ne i\\\\\n",
      "a^m_i(1 - a^m_i) a^{L - 1}_j & k = i\n",
      "\\end{cases}\n",
      "\\end{align*}\n",
      "\n",
      "For the final layer ($m = L$), the first term is straightforward to compute:\n",
      "\n",
      "$$\\frac{\\partial E}{\\partial a^L_k} = \\frac{\\partial}{\\partial a^L_k}\\frac{1}{2}(z - a^L)^\\top(z - a^L) = z_k - a^L_k$$\n",
      "\n",
      "For other layers, we must again invoke the chain rule:\n",
      "\n",
      "\\begin{align*}\n",
      "\\frac{\\partial E}{\\partial a^m_k} &= \\frac{\\partial E}{\\partial a^L_\\alpha} \\frac{\\partial a^L_\\alpha}{\\partial a^{L - 1}_\\beta} \\cdots \\frac{\\partial a^{m + 1}_\\omega}{\\partial a^m_k}\\\\\n",
      "&= (a^L_\\alpha - z_\\alpha)a^L_\\alpha(1 - a^L_\\alpha)W^L_{\\alpha\\beta} \\cdots a^{m + 1}_\\omega(1 - a^{m + 1}_\\omega)W^{m + 1}_{\\omega k}\n",
      "\\end{align*}\n",
      "\n",
      "\n",
      "The fact that $\\frac{\\partial E}{\\partial a^L_k}$ is $0$ unless $k = i$ causes the summation in $\\frac{\\partial E}{\\partial a^L_k}$ to collapse, giving\n",
      "\n",
      "$$\\frac{\\partial E}{\\partial W^L_{ij}} = (a^L_i - z_i)a^L_i(1 - a^L_i) a^{L - 1}_j$$\n",
      "\n",
      "\n",
      "\n",
      "Similarly, we have\n",
      "\n",
      "\\begin{align*}\n",
      "\\frac{\\partial E}{\\partial b^L_i} &= \\frac{\\partial E}{\\partial a^L_i} \\frac{\\partial a^L_i}{b^L_i}\\\\\n",
      "\\frac{\\partial a^L_i}{\\partial b^L_i} &= \\frac{\\partial a^L_i}{\\partial h_i^L} \\frac{\\partial h_i^L}{\\partial b^L_{ij}}\\\\\n",
      "&= a^L_i(1 - a^L_i)\\\\\n",
      "\\rightarrow \\frac{\\partial E}{\\partial b^L_i} &= (a^L_i - z_i)a^L_i(1 - a^L_i)\n",
      "\\end{align*}\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Backpropagation\n",
      "\n",
      "In order to train the network using a gradient descent algorithm, we need to know the gradient of each of the parameters with respect to the error function $\\frac{\\partial E}{\\partial W^m}$ and $\\frac{\\partial E}{\\partial b^m}$.  In order to compute the gradient of our error function to $W^m_{ij}$ (a single entry in the weight matrix of the layer $m$), we can use the chain rule:\n",
      "\n",
      "$$\\frac{\\partial E}{\\partial W^m_{ij}} = \\sum_{k = 1}^{N^m} \\frac{\\partial E}{\\partial h^m_k} \\frac{\\partial h^m_k}{\\partial W^m_{ij}}$$\n",
      "\n",
      "Note that the second term will evaluate to zero when $i \\ne k$ because $a^m_k$ does not interact with any elements in $W^m$ except for those in the $k$th row, and we are only considering the entry $W^m_{ij}$.  When $i = k$, we have\n",
      "\n",
      "\\begin{align*}\n",
      "\\frac{\\partial h^m_i}{\\partial W^m_{ij}} &= \\frac{\\partial}{\\partial W^m_{ij}}(W^m a^{m - 1} + b^m)\\\\\n",
      "&= a^{m - 1}_j\\\\\n",
      "\\rightarrow \\frac{\\partial h^m_k}{\\partial W^m_{ij}} &= \\begin{cases}\n",
      "0 & k \\ne i\\\\\n",
      "a^{m - 1}_j & k = i\n",
      "\\end{cases}\n",
      "\\end{align*}\n",
      "\n",
      "For the final layer ($m = L$), the first term is straightforward to compute using the chain rule:\n",
      "\n",
      "\\begin{align*}\n",
      "\\frac{\\partial E}{\\partial h^L_k} &= \\frac{\\partial E}{\\partial a^L_k} \\frac{\\partial a^L_k}{\\partial h^L_k}\\\\\n",
      "&= \\frac{\\partial}{\\partial a^L_k} \\frac{1}{2}(z - a^L)^\\top(z - a^L) \\frac{\\partial}{\\partial h^L_k} \\sigma^m(h^L_k)\\\\\n",
      "&= (z_k - a^L_k)a^L_k(1 - a^L_k)\n",
      "\\end{align*}\n",
      "\n",
      "For other layers, we must again invoke the chain rule:\n",
      "\n",
      "\\begin{align*}\n",
      "\\frac{\\partial E}{\\partial h^m_k} &= \\frac{\\partial E}{\\partial a^m_k} \\frac{\\partial a^m_k}{\\partial h^m_k}\\\\\n",
      "&= \\sum_{l = 1}^{N^{m + 1}}\\frac{\\partial E}{\\partial h^{m + 1}_l}\\frac{\\partial h^{m + 1}_l}{\\partial a^m_k}\\frac{\\partial a^m_k}{\\partial h^m_k}\\\\\n",
      "&= \\sum_{l = 1}^{N^{m + 1}}\\frac{\\partial E}{\\partial h^{m + 1}_l}\\frac{\\partial}{\\partial a^m_k} \\left(\\sum_{h = 1}^{N^m} W^{m + 1}_{lh} a_h^m + b_l^{m + 1}\\right) \\frac{\\partial}{\\partial h^m_k} \\sigma^m(h^m_k)\\\\\n",
      "&= \\sum_{l = 1}^{N^{m + 1}}\\frac{\\partial E}{\\partial h^{m + 1}_l} W^{m + 1}_{lk} a_k^m (1 - a_k^m)\\\\\n",
      "&= \\sum_{l = 1}^{N^{m + 1}}W^{m + 1\\top}_{kl} \\frac{\\partial E}{\\partial h^{m + 1}_l}  a_k^m (1 - a_k^m)\\\\\n",
      "\\end{align*}\n",
      "\n",
      "The vector form follows:\n",
      "\n",
      "$$\\frac{\\partial E}{\\partial h^m} = \\left(W^{m + 1\\top} \\frac{\\partial E}{\\partial h^{m + 1}}\\right) \\circ a^m \\circ (1 - a^m)$$\n",
      "\n",
      "\n",
      "The fact that $\\frac{\\partial E}{\\partial a^L_k}$ is $0$ unless $k = i$ causes the summation in $\\frac{\\partial E}{\\partial a^L_k}$ to collapse, giving\n",
      "\n",
      "$$\\frac{\\partial E}{\\partial W^L_{ij}} = (a^L_i - z_i)a^L_i(1 - a^L_i) a^{L - 1}_j$$\n",
      "\n",
      "\n",
      "We will derive the backpropogation algorithm for a neural network with a logistic activation function on all layers; that is \n",
      "\n",
      "$$\\sigma^m(x) = \\frac{1}{1 + e^{x}}$$\n",
      "\n",
      "for all $m \\in \\{1, \\ldots, L\\}$.  The logistic activation function has derivative\n",
      "\n",
      "$$\\frac{\\partial \\sigma^m}{\\partial x} = \\sigma^m(x)(1 - \\sigma^m(x))$$\n",
      "\n",
      "Because the network is updated for each training example individually, we will perform all derivations for a single training vector $x$ and a target $z$.  We will use the squared error function\n",
      "\n",
      "$$E = \\frac{1}{2}(z - a^L)^\\top(z - a^L)$$\n",
      "\n",
      "\n",
      "Similarly, we have\n",
      "\n",
      "\\begin{align*}\n",
      "\\frac{\\partial E}{\\partial b^L_i} &= \\frac{\\partial E}{\\partial a^L_i} \\frac{\\partial a^L_i}{b^L_i}\\\\\n",
      "\\frac{\\partial a^L_i}{\\partial b^L_i} &= \\frac{\\partial a^L_i}{\\partial h_i^L} \\frac{\\partial h_i^L}{\\partial b^L_{ij}}\\\\\n",
      "&= a^L_i(1 - a^L_i)\\\\\n",
      "\\rightarrow \\frac{\\partial E}{\\partial b^L_i} &= (a^L_i - z_i)a^L_i(1 - a^L_i)\n",
      "\\end{align*}\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "| Nonlinearity | $\\sigma^m(h^m)$         | $\\frac{\\partial a^m}{\\partial z^m}$                |\n",
      "| Sigmoid      | $\\frac{1}{1 + e^(h^m)}$ | $\\frac{1}{1 + e^{h^m}}\\frac{e^{h^m}}{1 + e^{h^m}}$ |"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "np.random.seed(0)\n",
      "\n",
      "def tanh(x):\n",
      "    return np.tanh(x)\n",
      "\n",
      "def tanh_deriv(x):\n",
      "    return 1.0 - x**2\n",
      "\n",
      "def logistic(x):\n",
      "    return 1/(1 + np.exp(-x))\n",
      "\n",
      "def logistic_derivative(x):\n",
      "    return logistic(x)*(1-logistic(x))\n",
      "\n",
      "class NeuralNetwork:\n",
      "\n",
      "    def __init__(self, layers, activation='tanh'):\n",
      "        \"\"\"\n",
      "        :param layers: A list containing the number of units in each layer. Should be at least two values\n",
      "        :param activation: The activation function to be used. Can be \"logistic\" or \"tanh\"\n",
      "        \"\"\"\n",
      "        if activation == 'logistic':\n",
      "            self.activation = logistic\n",
      "            self.activation_deriv = logistic_derivative\n",
      "        elif activation == 'tanh':\n",
      "            self.activation = tanh\n",
      "            self.activation_deriv = tanh_deriv\n",
      "\n",
      "        self.weights = []\n",
      "        for i in range(1, len(layers) - 1):\n",
      "            self.weights.append((2*np.random.random((layers[i - 1], layers[i]))-1)*0.25)\n",
      "        self.weights.append((2*np.random.random((layers[i], layers[i + 1]))-1)*0.25)\n",
      "        \n",
      "    def fit(self, X, y, learning_rate=0.2, epochs=10000):\n",
      "        X = np.atleast_2d(X)\n",
      "        #temp = np.ones([X.shape[0], X.shape[1]+1])\n",
      "        #temp[:, 0:-1] = X  # adding the bias unit to the input layer\n",
      "        #X = temp\n",
      "        y = np.array(y)\n",
      "\n",
      "        for k in range(epochs):\n",
      "            i = np.random.randint(X.shape[0])\n",
      "            a = [X[i]]\n",
      "\n",
      "            for l in range(len(self.weights)):\n",
      "                    a.append(self.activation(np.dot(a[l], self.weights[l])))\n",
      "            error = y[i] - a[-1]\n",
      "            deltas = [error * self.activation_deriv(a[-1])]\n",
      "\n",
      "            for l in range(len(a) - 2, 0, -1): # we need to begin at the second to last layer\n",
      "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_deriv(a[l]))\n",
      "            deltas.reverse()\n",
      "            for i in range(len(self.weights)):\n",
      "                layer = np.atleast_2d(a[i])\n",
      "                delta = np.atleast_2d(deltas[i])\n",
      "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
      "\n",
      "    def predict(self, x):\n",
      "        x = np.array(x)\n",
      "        #temp = np.ones(x.shape[0]+1)\n",
      "        #temp[0:-1] = x\n",
      "        a = x#temp\n",
      "        for l in range(0, len(self.weights)):\n",
      "            a = self.activation(np.dot(a, self.weights[l]))\n",
      "        return a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NeuralNetwork([2,2,1], 'tanh')\n",
      "X = np.array([[0, 0],\n",
      "              [0, 1],\n",
      "              [1, 0],\n",
      "              [1, 1]])\n",
      "y = np.array([1, 0, 1, 0])\n",
      "nn.fit(X, y)\n",
      "for i in [[0, 0], [0, 1], [1, 0], [1, 1]]:\n",
      "    print i, nn.predict(i)#1*(nn.predict(i) > .5).flatten()[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0, 0] [ 0.]\n",
        "[0, 1] [-0.00941255]\n",
        "[1, 0] [ 0.97730902]\n",
        "[1, 1] [ 0.02821457]\n"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "np.random.seed(0)\n",
      "\n",
      "def tanh(x):\n",
      "    return np.tanh(x)\n",
      "\n",
      "def tanh_deriv(x):\n",
      "    return 1.0 - x**2\n",
      "\n",
      "def logistic(x):\n",
      "    return 1/(1 + np.exp(-x))\n",
      "\n",
      "def logistic_derivative(x):\n",
      "    return logistic(x)*(1-logistic(x))\n",
      "\n",
      "class NeuralNetwork:\n",
      "\n",
      "    def __init__(self, layers, activation='tanh'):\n",
      "        \"\"\"\n",
      "        :param layers: A list containing the number of units in each layer. Should be at least two values\n",
      "        :param activation: The activation function to be used. Can be \"logistic\" or \"tanh\"\n",
      "        \"\"\"\n",
      "        if activation == 'logistic':\n",
      "            self.activation = logistic\n",
      "            self.activation_deriv = logistic_derivative\n",
      "        elif activation == 'tanh':\n",
      "            self.activation = tanh\n",
      "            self.activation_deriv = tanh_deriv\n",
      "\n",
      "        self.weights = []\n",
      "        self.biases = []\n",
      "        for i in range(1, len(layers)):\n",
      "            self.weights.append(.5*np.random.random((layers[i], layers[i - 1])) - 0.25)\n",
      "            self.biases.append(.5*np.random.random((layers[i], 1)) - 0.25)\n",
      "        \n",
      "    def train(self, X, z, learning_rate=0.2):\n",
      "        # Convert arrays to column vectors\n",
      "        if X.ndim == 1:\n",
      "            X = X.reshape(-1, 1)\n",
      "        if z.ndim == 1:\n",
      "            z = z.reshape(-1, 1)\n",
      "            \n",
      "        a = [self.activation(np.dot(self.weights[0], X))]# + self.biases[0]]\n",
      "\n",
      "        # Forward pass\n",
      "        for m in xrange(1, len(self.weights)):\n",
      "            # a^m = sigma^m(W^m a^(m - 1) + b^m)\n",
      "            a.append(self.activation(np.dot(self.weights[m], a[m - 1])))# + self.biases[m])\n",
      "        # \\delta^L = (z - a^L) o a^L o (1 - a^L)\n",
      "        deltas = [(z - a[-1])*self.activation_deriv(a[-1])]\n",
      "\n",
      "        # For layers from L - 1 to 1\n",
      "        for m in reversed(xrange(len(a) - 1)):\n",
      "            # (W^{(m + 1)T} \\delta^{m + 1}) o a^m o (1 - a^m)\n",
      "            deltas.append(np.dot(self.weights[m + 1].T, deltas[-1])*self.activation_deriv(a[m]))\n",
      "        deltas.reverse()\n",
      "        #print [b.shape for b in a] \n",
      "        #print [w.shape for w in self.weights]\n",
      "        #print [d.shape for d in deltas]\n",
      "        self.weights[0] += learning_rate*np.dot(deltas[0], X.T)\n",
      "        for m in range(1, len(self.weights)):\n",
      "            self.weights[m] += learning_rate*np.dot(deltas[m], a[m - 1].T)\n",
      "            #self.biases[m] += learning_rate*deltas[m]\n",
      "\n",
      "    def predict(self, X):\n",
      "        if X.ndim == 1:\n",
      "            X = X.reshape(-1, 1)\n",
      "        a = X\n",
      "        for m in xrange(len(self.weights)):\n",
      "            a = self.activation(np.dot(self.weights[m], a))# + self.biases[m]\n",
      "        return a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NeuralNetwork([2, 3, 4, 7, 1], 'tanh')\n",
      "X = np.array([[0, 0, 1, 1],\n",
      "              [0, 1, 0, 1]])\n",
      "z = np.array([[0, 1, 1, 0]])\n",
      "for n in xrange(10000):\n",
      "    i = np.random.choice(X.shape[1])\n",
      "    nn.train(X[:, i], z[:, i])\n",
      "print X\n",
      "print 1*(nn.predict(X) > .5)\n",
      "print nn.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 0 1 1]\n",
        " [0 1 0 1]]\n",
        "[[0 1 1 0]]\n",
        "[[ 0.          0.99299805  0.99071787 -0.02635698]]\n"
       ]
      }
     ],
     "prompt_number": 219
    }
   ],
   "metadata": {}
  }
 ]
}